{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "How would you define Machine Learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular definitions of machine learning are the more general educational one\n",
    "\n",
    "\"The ability of a machine to learn without being explicitly programmed to do so\"\n",
    "\n",
    "and the more rigorous\n",
    "\n",
    "\"A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance in task T, as measured by P, improves with experience E\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Can you name 4 types of applications where it shines?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex problems that don't have a known algorithmic solution (e.g. speech recognition), problems\n",
    "that study fluctuating data that changes with time (e.g. weather forecasting), problems that\n",
    "were traditionally solved by an expert system which is a program with a long list of hard-coded rules\n",
    "(e.g. illness prediction), and\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "What is a labeled training set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training set is labeled when every data point contains a value for the target variable, $y^{(i)}$. The target variable is the variable that the model is trying to predict. In a labeled dataset each point has the actual measured value of the variable we are trying to predict, that's why it is often said that a labeled dataset has data with the right answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "What are the two most common supervised tasks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification, where the target is a categorical value, and regression, where the target is a continuous numerical variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Can you named 4 common unsupervised tasks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering, anomaly detection, dimensionality reduction, and visualization algorithms for high dimensional data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "What type of algorithm would you use to allow a robot to walk in various unknown terrains?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use reinforcement learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "What type of algorithm would you use to segment your customers into multiple groups?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clustering algorithm, which is a type of unsupervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that you would use in such a problem should contain many emails, each labeled as spam or not spam. Therefore, the dataset is labeled and this is a supervised learning problem, more specifically a binary classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "What is an online learning system?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An online learning system is a system that is able to incrementally learn from new data, without having to be trained from scratch each time there is a new data point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "What is out-of-core learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with huge datasets or with machines that are very performance limited, such as mobile devices, it is often impossible to train a ML model at once (the dataset may not in even fit in storage). In such cases, the dataset is chopped up in mini-batches that are used to incrementally train the model with more data, leveraging the advantages of online learning. This is calle out-of-core learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "What type of algorithm relies on a similarity measure to make predictions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A case-based algorithm. In this type of algorithm, the prediction is made based only on the points of the training data that are most similar to the new point that the algorithm is trying to predict. This algorithms naturally requires some sort of similarity measurement to make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "What is the difference between a model parameter and hyperparameter?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is a function $f_{\\vec{w}}(\\vec{x})$ that attempts to predict the value of the target variable $y$ based on the value of the input variable $\\vec{x}$, the model parameters are the parameters of that function $\\vec{w}$. When the model is fitted to a training set, the parameters are optimized to minimize a cost function.\n",
    "\n",
    "The hyperparameters are the values that control the size of the parameters. This is done by including the hyperparameters inside the cost function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "\n",
    "What do model based algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They search for the function $f$ that maps the features $\\vec{x}$ to the labels $\\vec{y}$ with the smallest possible error. The function depends on a series of parameters, $\\vec{w}, b$ that are optimized to minimize the error (more precisely, the cost function). To predict the label $\\hat{y}^{(i)}$ of a data point $\\vec{x}^{(1)}$, the model applies the function to that data point: $\\hat{y}^{(i)} = f_{\\vec{w}, b}(\\vec{x}^{(i)})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14\n",
    "\n",
    "Can you name 4 of the main challenges in Machine Learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting/underfitting, nonrepresentative data, poor quality data, and insufficient quality of training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15\n",
    "\n",
    "If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name 3 possible solutions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a textbook example of overfitting. You can fix it by changing the model (regularization: constraining the parameters, choosing a simpler model with less parameters) or the dataset (reducing the number of features, reducing the noisiness by cleaning the data, collecting more data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 16\n",
    "\n",
    "What is a test set and why would you want to use it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test set is a fraction of the original data set that is put away for testing the model and won't be used for training. Ideally only the final model will be tested on this set, i.e. you should avoid testing multiple models on the test set to avoid overfitting. You want to use a test set because the only way to know how a model will perform on new data that it has never seen before is to actually test it on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 17\n",
    "\n",
    "What is the purpose of a validation set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of a validation set is hyperparameter tuning and model selection. You can train select different models and hyperparameters, test them in the validation set, and keep the best performer. However you should be careful to avoid overfitting: if you try too many models you run the risk of selecting the model that fits your very specific validation set. To avoid this you can use cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 18\n",
    "\n",
    "What is the train-dev set, when do you need it and how do you use it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its yet another partition of the dataset that is used in the cases of data mismatch, that is when you are forced to train the model with data that is not representative of the data that it will see once it's deployed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 19\n",
    "\n",
    "What can go wrong if you tune hyperparameters using the test set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select the hyperparameter that optimally fits your very specific test set. This is a case of overfitting and it will most likely not generalize well. Also the error of this model won't be the true out of sample error, and you have no idea of what is the error of the model with new data.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
